---
title: 台大李宏毅机器学习——深度学习的必要性
categories: 统计学习
mathjax: true
date: 2017-09-15
---

现在我们来考虑一下，模型是不是越深越好。
<!--more-->

如果我们要比较深度网络或者浅层网络，做公平比较的时候，深度网络和浅层网络直接需要设定的参数量是一致的才行。也就是说，深度网络可以瘦一点，而浅层网络就要胖一点。下图是一个比较：

<img src=https://raw.githubusercontent.com/SamaelChen/samaelchen.github.io/hexo/images/blog/ml056.png>

我们可以看到实际上，当参数一样的时候，层数越深，效果越好。那为什么会发生这样的情况？

从某种程度上而言，深度学习的结构是很像集成算法的。我们可以将前面的每一层都看成是多个弱分类器，最后根据多个弱分类器得到一个最终结果。

那事实上，这样的结构在一定程度上可以做到一定的举一反三，因此从某种程度而言，实际上正是因为数据量不够，所以我们才需要机器学习。如果现在真的有真正的big data，那根本不需要机器来做举一反三的事情。所以把大数据等同于AI，或者所谓大数据+深度学习=AI的，根本就是呵呵哒。

举个例子来说的话，深度学习做的事情有点像是剪窗花，通过多次对折，只要剪几次就能得到一个漂亮的窗花。下面是一个类似的例子：

<img src=https://raw.githubusercontent.com/SamaelChen/samaelchen.github.io/hexo/images/blog/ml057.png>

那我们可以看到，当数据量足够多的时候，单层神经网络也能有很好的结果，但是当数量只有2w笔的时候，三层网络崩坏的比较有规律。

那现在回过头想一下，我们说单层神经网络，只要neuron足够多，就可以拟合任意的连续函数。那么为什么我们要使用深层网络呢？其实用深层网络可以更高效实现这样的事情，因此我们偏向使用深度学习。另外很复杂的模型可以做到下面的例子：

<img src=https://raw.githubusercontent.com/SamaelChen/samaelchen.github.io/hexo/images/blog/ml058.png>

那么，既然理论上单层就能做到的事情，是不是实践上完全不可能做到多层的效果呢？也不是，微软的Rich提到，如果单层网络不去直接学习真实的label，而是去学习三层网络的output，实际上也能达到三层网络的效果。其实就是让单层网络去学习多层网络的特征。

嗯，今天被教育了，多动手，少逼逼，不要浪。进步从复现论文效果开始。
